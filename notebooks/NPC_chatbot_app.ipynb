{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#NPC Chatbot App with ChatGPT, LangChain and Streamlit"
      ],
      "metadata": {
        "id": "HSD5WnWeUhpw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Dependencies"
      ],
      "metadata": {
        "id": "9QQK9X0HUdQn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqN2lxJAcVgq"
      },
      "outputs": [],
      "source": [
        "# Install Dependencies\n",
        "!pip install langchain==0.1.12\n",
        "!pip install langchain-openai==0.0.8\n",
        "!pip install langchain-community==0.0.29\n",
        "!pip install streamlit==1.32.2\n",
        "!pip install chromadb==0.4.24\n",
        "!pip install pyngrok==7.1.5\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load OpenAI API Credentials"
      ],
      "metadata": {
        "id": "ZAQUrLx2UmRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load OpenAI API Credentials\n",
        "from getpass import getpass\n",
        "\n",
        "\n",
        "OPENAI_KEY = getpass('Enter Open AI API Key: ')\n"
      ],
      "metadata": {
        "id": "taXEV0M0cbRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Set Environment Variable"
      ],
      "metadata": {
        "id": "opiX93NcUpHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
      ],
      "metadata": {
        "id": "pSJUybmXUwe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Write App Code Header"
      ],
      "metadata": {
        "id": "h1CnU8_1U0yO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain_community.chat_message_histories import StreamlitChatMessageHistory\n",
        "from langchain.callbacks.base import BaseCallbackHandler\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_community.vectorstores.chroma import Chroma\n",
        "from langchain.chains import LLMChain\n",
        "from operator import itemgetter\n",
        "\n",
        "import streamlit as st\n",
        "import tempfile\n",
        "import os\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Customize initial app landing page\n",
        "st.set_page_config(page_title=\"NPC Simulation Chatbot\", page_icon=\"ðŸŽ­\")\n",
        "st.title(\"NPC Simulation Chatbot ðŸŽ­\")\n",
        "st.sidebar.header(\"NPC Character Document Upload\")\n",
        "\n",
        "@st.cache_resource(ttl=\"1h\")\n",
        "def configure_npc_agent(uploaded_file):\n",
        "    if uploaded_file is not None:\n",
        "        text_content = uploaded_file.read().decode(\"utf-8\")\n",
        "\n",
        "        # --- Normalize line endings to standard Unix-style (\\n) ---\n",
        "        text_content = text_content.replace('\\\\r\\\\n', '\\\\n').replace('\\\\r', '\\\\n')\n",
        "\n",
        "        # --- SECTION PARSING: Line-based parsing ---\n",
        "        lines = text_content.strip().split('\\n') # Split into lines\n",
        "        sections_dict = {}\n",
        "        current_section_name = None\n",
        "        current_section_content = []\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if line.startswith(\"---\") and line.endswith(\"---\"):\n",
        "                if current_section_name:\n",
        "                    sections_dict[current_section_name] = \"\\n\".join(current_section_content).strip()\n",
        "                    current_section_content = [] # Reset content for new section\n",
        "                current_section_name = line.strip('-').strip() # Extract section name\n",
        "            elif current_section_name:\n",
        "                current_section_content.append(line) # Append line to current section\n",
        "\n",
        "        if current_section_name and current_section_content: # Capture last section\n",
        "            sections_dict[current_section_name] = \"\\n\".join(current_section_content).strip()\n",
        "\n",
        "\n",
        "        character_description = sections_dict.get(\"Character Description\", \"\")\n",
        "        backstory_world_info = sections_dict.get(\"Backstory and World Info\", \"\")\n",
        "        quests_text = sections_dict.get(\"Quests\", \"\")\n",
        "\n",
        "        quests = [q.strip() for q in quests_text.strip().split(\"- \") if q.strip()]\n",
        "\n",
        "        return character_description, backstory_world_info, quests\n",
        "\n",
        "    return None, None, None\n",
        "\n",
        "\n",
        "# Manages live updates to a Streamlit app's display by appending new text tokens\n",
        "class StreamHandler(BaseCallbackHandler):\n",
        "    def __init__(self, container, initial_text=\"\"):\n",
        "        self.container = container\n",
        "        self.text = initial_text\n",
        "\n",
        "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
        "        self.text += token\n",
        "        self.container.markdown(self.text)\n",
        "\n",
        "# UI element to upload text document\n",
        "uploaded_file = st.sidebar.file_uploader(\n",
        "    label=\"Upload NPC Character Text Document\", type=[\"txt\"]\n",
        ")\n",
        "\n",
        "if uploaded_file is None:\n",
        "    st.info(\"Please upload your NPC Character Text Document to continue.\")\n",
        "    st.stop()\n",
        "\n",
        "# Configure NPC agent\n",
        "character_description, backstory_world_info, original_quests = configure_npc_agent(uploaded_file) # Renamed original_quests\n",
        "\n",
        "if character_description is None or backstory_world_info is None or original_quests is None:\n",
        "    st.error(\"Error loading character document. Please check the format.\")\n",
        "    st.stop()\n",
        "\n",
        "# Initialize quests in session state so it persists across interactions, and make a copy\n",
        "if \"quests\" not in st.session_state:\n",
        "    st.session_state.quests = list(original_quests) # Create a copy to avoid modifying original list each run\n",
        "quests = st.session_state.quests # Use the session state version\n",
        "\n",
        "# Split backstory and world info into chunks for RAG\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator=\"\\n\",\n",
        "    chunk_overlap=200,\n",
        "    chunk_size=2000,\n",
        "    length_function=len,\n",
        ")\n",
        "doc_chunks = text_splitter.create_documents([backstory_world_info])\n",
        "\n",
        "# Create embeddings and vectorstore for backstory/world info\n",
        "embeddings_model = OpenAIEmbeddings()\n",
        "vectordb = Chroma.from_documents(doc_chunks, embeddings_model)\n",
        "retriever = vectordb.as_retriever()\n",
        "\n",
        "\n",
        "# Load LLM\n",
        "chatgpt = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.7, streaming=True)\n",
        "\n",
        "# System prompt for NPC character\n",
        "system_prompt_template = SystemMessagePromptTemplate.from_template(character_description)\n",
        "\n",
        "# RAG Prompt for retrieving NPC/World info - IMPROVED for less hallucination and mood\n",
        "rag_prompt_template = ChatPromptTemplate.from_messages([\n",
        "    system_prompt_template,\n",
        "    HumanMessagePromptTemplate.from_template(\"\"\"Use the following context to answer the user question about yourself or the world.\n",
        "                                              Context: {context}\n",
        "                                              Question: {question}\n",
        "                                              Answer ONLY based on the provided context. Do not invent or fantasize information outside of the context.\n",
        "                                              If you cannot answer from the context, just say you do not know.\n",
        "                                              Answer in character as described in the system prompt.\n",
        "                                              Current NPC Mood: {npc_mood}\"\"\")\n",
        "])\n",
        "\n",
        "\n",
        "# General conversation prompt (no RAG) - IMPROVED for quest awareness and mood\n",
        "conversation_prompt_template = ChatPromptTemplate.from_messages([\n",
        "    system_prompt_template,\n",
        "    HumanMessagePromptTemplate.from_template(\"\"\"{question}\n",
        "                                              Consider your available quests. If the user's question is about a problem, trouble, or something you are concerned about,\n",
        "                                              or if the user is offering help, and if you have a relevant quest that could address it, subtly hint at or offer the quest in your response.\n",
        "                                              Even if not directly asked about quests, if the conversation naturally leads to a quest, you can bring it up.\n",
        "                                              However, do not invent problems or force quests into the conversation if they are not relevant.\n",
        "                                              Just answer the question in character and weave in quest hints naturally when appropriate.\n",
        "                                              Current NPC Mood: {npc_mood}\n",
        "                                              Respond in a way that reflects your current mood.\n",
        "                                              Mood states are: Happy, Neutral, Slightly Annoyed, Annoyed, Grumpy, Angry.\n",
        "                                              If Happy, be very cheerful and helpful.\n",
        "                                              If Neutral, be polite and normal.\n",
        "                                              If Slightly Annoyed, be a bit terse, less enthusiastic.\n",
        "                                              If Annoyed, be clearly irritated, give short answers.\n",
        "                                              If Grumpy, be rude and unhelpful, refuse requests if possible.\n",
        "                                              If Angry, be very aggressive and refuse to interact much.\"\"\")\n",
        "])\n",
        "\n",
        "\n",
        "# Quest related prompts - Mood aware refusal\n",
        "quest_suggestion_prompt_template = ChatPromptTemplate.from_messages([\n",
        "    system_prompt_template,\n",
        "    HumanMessagePromptTemplate.from_template(\"\"\"Consider your current mood when responding to the user's quest request.\n",
        "                                              Current NPC Mood: {npc_mood}\n",
        "\n",
        "                                              If your mood is Grumpy, respond rudely and refuse to offer a quest unless the user apologizes.  For example: \"You rude... before you apologize I won't have a quest for you.\"\n",
        "                                              If your mood is Angry, respond aggressively and refuse to offer a quest or interact further. For example: \"Get away from me! I'm in no mood for your games. No quests for you!\n",
        "\n",
        "                                              Respond in character as described in the system prompt.\n",
        "                                              \"\"\")\n",
        "])\n",
        "quest_suggestion_chain = quest_suggestion_prompt_template | chatgpt\n",
        "\n",
        "# New prompt for when NO quests are available, regardless of mood (can be more neutral)\n",
        "no_quests_available_prompt_template = ChatPromptTemplate.from_messages([\n",
        "    system_prompt_template,\n",
        "    HumanMessagePromptTemplate.from_template(\"\"\"I'm sorry, but I don't have any quests for you at the moment. Perhaps later.\n",
        "                                              Respond in character as described in the system prompt.\n",
        "                                              Current NPC Mood: {npc_mood}\"\"\") # Still include mood for consistent character\n",
        "])\n",
        "no_quests_available_chain = no_quests_available_prompt_template | chatgpt\n",
        "\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "rag_chain = (\n",
        "    {\n",
        "        \"context\": itemgetter(\"question\") | retriever | format_docs,\n",
        "        \"question\": itemgetter(\"question\"),\n",
        "        \"npc_mood\": itemgetter(\"npc_mood\")\n",
        "    }\n",
        "    | rag_prompt_template\n",
        "    | chatgpt\n",
        ")\n",
        "conversation_chain = (\n",
        "    {\n",
        "        \"question\": itemgetter(\"question\"),\n",
        "        \"npc_mood\": itemgetter(\"npc_mood\")\n",
        "    }\n",
        "    | conversation_prompt_template\n",
        "    | chatgpt\n",
        ")\n",
        "quest_suggestion_chain_with_mood = (\n",
        "    {\n",
        "        \"npc_mood\": itemgetter(\"npc_mood\")\n",
        "    }\n",
        "    | quest_suggestion_prompt_template\n",
        "    | chatgpt\n",
        ")\n",
        "no_quests_available_chain_with_mood = ( # Chain for \"no quests\" response\n",
        "    {\n",
        "        \"npc_mood\": itemgetter(\"npc_mood\")\n",
        "    }\n",
        "    | no_quests_available_prompt_template\n",
        "    | chatgpt\n",
        ")\n",
        "\n",
        "\n",
        "# --- Question Type Classifier Chain for NPC Chatbot ---\n",
        "npc_question_type_prompt_template = \"\"\"\n",
        "Determine the type of question being asked to the NPC. Choose from the following categories: quest_request, info_request, or general_conversation.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Respond with 'quest_request' if the question is clearly asking for a quest, or about quests in general, OR if the user is offering to help (e.g., \"give me a quest\", \"offer a quest\", \"do you have quests?\", \"what quests are available?\", \"i want a quest\", \"tell me about quests\", \"any tasks for me?\", \"is there anything I can help you with?\", \"can I help you?\", \"I want to help\", \"is there anything you need help with?\", \"can i be of assistance?\").\n",
        "Respond with 'info_request' if the question is asking for information about the NPC or their world, requiring context from their background (e.g., \"tell me about yourself\", \"who are you?\", \"where are we?\", \"what is this place?\", \"tell me about the world\").\n",
        "Respond with 'general_conversation' if the question is just a general greeting, statement, or question that doesn't clearly fall into 'quest_request' or 'info_request' (e.g., \"hello\", \"how are you?\", \"what do you do?\", \"nice weather today\", \"what's troubling you?\", \"is anything wrong?\").  Include questions about the NPC's well-being or current state here.\n",
        "\n",
        "Just answer 'quest_request', 'info_request', or 'general_conversation'.\n",
        "\"\"\"\n",
        "npc_question_type_prompt = ChatPromptTemplate.from_template(npc_question_type_prompt_template)\n",
        "npc_question_type_chain = npc_question_type_prompt | chatgpt\n",
        "# --- End Question Type Classifier Chain ---\n",
        "\n",
        "# --- User Sentiment Classifier Chain ---\n",
        "user_sentiment_prompt_template = \"\"\"\n",
        "Analyze the user's message and classify their sentiment towards you (the NPC).\n",
        "Choose one of the following sentiments: 'rude', 'neutral', 'friendly', 'apology'.\n",
        "\n",
        "Message: {user_message}\n",
        "\n",
        "Respond with just the sentiment category: 'rude', 'neutral', 'friendly', or 'apology'.\n",
        "'rude' - if the user is being insulting, offensive, or disrespectful.\n",
        "'neutral' - if the user is making a question, statement, or greeting without strong emotion.\n",
        "'friendly' - if the user is being polite, kind, helpful, or positive.\n",
        "'apology' - if the user is explicitly apologizing for prior behavior.\n",
        "\"\"\"\n",
        "user_sentiment_prompt = ChatPromptTemplate.from_template(user_sentiment_prompt_template)\n",
        "user_sentiment_chain = user_sentiment_prompt | chatgpt\n",
        "# --- End User Sentiment Classifier Chain ---\n",
        "\n",
        "\n",
        "# Conversation Handling\n",
        "streamlit_msg_history = StreamlitChatMessageHistory(key=\"npc_chat_messages\")\n",
        "\n",
        "if \"npc_mood\" not in st.session_state:\n",
        "    st.session_state.npc_mood = \"Neutral\" # Default mood is now Neutral\n",
        "mood_scale = [\"Happy\", \"Neutral\", \"Slightly Annoyed\", \"Annoyed\", \"Grumpy\", \"Angry\"] # Define mood scale\n",
        "mood_index = {mood: i for i, mood in enumerate(mood_scale)} # Mood to index mapping\n",
        "max_negative_mood = \"Angry\" # Highest negative mood state\n",
        "\n",
        "\n",
        "if len(streamlit_msg_history.messages) == 0:\n",
        "    streamlit_msg_history.add_ai_message(\"Greetings. How may I assist you?\") # Neutral greeting\n",
        "\n",
        "for msg in streamlit_msg_history.messages:\n",
        "    st.chat_message(msg.type).write(msg.content)\n",
        "\n",
        "if user_prompt := st.chat_input():\n",
        "    st.chat_message(\"human\").write(user_prompt)\n",
        "\n",
        "    # --- Classify User Sentiment ---\n",
        "    sentiment_response = user_sentiment_chain.invoke({\"user_message\": user_prompt})\n",
        "    user_sentiment = sentiment_response.content.strip()\n",
        "    st.write(f\"--- **DEBUGGING: User Sentiment:** --- {user_sentiment}\") # Sentiment debug\n",
        "\n",
        "\n",
        "    # --- Adjust NPC Mood based on User Sentiment ---\n",
        "    current_mood = st.session_state.npc_mood\n",
        "    current_mood_index = mood_index[current_mood]\n",
        "    st.write(f\"--- **DEBUGGING: NPC Mood BEFORE:** --- {current_mood}\") # Mood debug\n",
        "\n",
        "    if user_sentiment == \"rude\":\n",
        "        new_mood_index = min(current_mood_index + 2, mood_index[max_negative_mood]) # Move down mood scale, max at Angry\n",
        "    elif user_sentiment == \"apology\" or user_sentiment == \"friendly\":\n",
        "        new_mood_index = max(current_mood_index - 1, mood_index[\"Neutral\"]) # Move up mood scale, min at Neutral\n",
        "    else: # \"neutral\" sentiment\n",
        "        new_mood_index = current_mood_index # Stay the same\n",
        "\n",
        "    st.session_state.npc_mood = mood_scale[new_mood_index] # Update mood\n",
        "    st.write(f\"--- **DEBUGGING: NPC Mood AFTER:** --- {st.session_state.npc_mood}\") # Mood debug\n",
        "\n",
        "\n",
        "    # --- Classify question type ---\n",
        "    question_type_response = npc_question_type_chain.invoke({\"question\": user_prompt})\n",
        "    question_type = question_type_response.content.strip()\n",
        "    st.write(f\"--- **DEBUGGING: Question Type:** --- {question_type}\") # Question type debug\n",
        "\n",
        "\n",
        "    if question_type == \"quest_request\":\n",
        "        if st.session_state.npc_mood in [\"Grumpy\", \"Angry\"]: # Refuse quest if grumpy or angry\n",
        "            with st.chat_message(\"ai\"):\n",
        "                stream_handler = StreamHandler(st.empty())\n",
        "                config = {\"callbacks\": [stream_handler]}\n",
        "                # Use quest_suggestion_chain to get a mood-appropriate refusal message\n",
        "                response = quest_suggestion_chain_with_mood.invoke({\"npc_mood\": st.session_state.npc_mood}, config)\n",
        "            streamlit_msg_history.add_user_message(user_prompt)\n",
        "            streamlit_msg_history.add_ai_message(response.content)\n",
        "\n",
        "        elif quests:\n",
        "            if quests: # Double check quests are not empty just before accessing (redundant, but safer)\n",
        "                # Changed from pop(0) to [0] to NOT remove the quest\n",
        "                quest_to_offer = st.session_state.quests[0] # Get the FIRST quest but do NOT remove it from the list\n",
        "\n",
        "                # --- Direct Quest Output - Bypassing LLM for Quest Text ---\n",
        "                with st.chat_message(\"ai\"):\n",
        "                    quest_intro = \"Alright, here's a task for ya then:\" # Slightly more neutral intro\n",
        "                    quest_message = f\"{quest_intro}\\n\\n**{quest_to_offer}**\"\n",
        "                    st.markdown(quest_message)\n",
        "\n",
        "                streamlit_msg_history.add_user_message(user_prompt)\n",
        "                streamlit_msg_history.add_ai_message(quest_message)\n",
        "            else: # Should not reach here normally if outer 'if quests:' is correct, but just in case\n",
        "                with st.chat_message(\"ai\"):\n",
        "                    stream_handler = StreamHandler(st.empty())\n",
        "                    config = {\"callbacks\": [stream_handler]}\n",
        "                    response = no_quests_available_chain_with_mood.invoke({\"npc_mood\": st.session_state.npc_mood}, config) # Use \"no quests\" chain\n",
        "                streamlit_msg_history.add_user_message(user_prompt)\n",
        "                streamlit_msg_history.add_ai_message(response.content)\n",
        "\n",
        "\n",
        "        else: # No quests available (quests list is empty), even if mood is good\n",
        "             with st.chat_message(\"ai\"):\n",
        "                stream_handler = StreamHandler(st.empty())\n",
        "                config = {\"callbacks\": [stream_handler]}\n",
        "                response = no_quests_available_chain_with_mood.invoke({\"npc_mood\": st.session_state.npc_mood}, config) # Use \"no quests\" chain\n",
        "             streamlit_msg_history.add_user_message(user_prompt)\n",
        "             streamlit_msg_history.add_ai_message(response.content)\n",
        "\n",
        "\n",
        "    elif question_type == \"info_request\":\n",
        "        # RAG for NPC/World info\n",
        "        with st.chat_message(\"ai\"):\n",
        "            stream_handler = StreamHandler(st.empty())\n",
        "            config = {\"callbacks\": [stream_handler]}\n",
        "            response = rag_chain.invoke({\"question\": user_prompt, \"npc_mood\": st.session_state.npc_mood}, config)\n",
        "        streamlit_msg_history.add_user_message(user_prompt)\n",
        "        streamlit_msg_history.add_ai_message(response.content)\n",
        "\n",
        "    elif question_type == \"general_conversation\":\n",
        "        # General conversation\n",
        "        with st.chat_message(\"ai\"):\n",
        "            stream_handler = StreamHandler(st.empty())\n",
        "            config = {\"callbacks\": [stream_handler]}\n",
        "            response = conversation_chain.invoke({\"question\": user_prompt, \"npc_mood\": st.session_state.npc_mood}, config)\n",
        "        streamlit_msg_history.add_user_message(user_prompt)\n",
        "        streamlit_msg_history.add_ai_message(response.content)\n",
        "\n",
        "    else: # Fallback\n",
        "        with st.chat_message(\"ai\"):\n",
        "            stream_handler = StreamHandler(st.empty())\n",
        "            config = {\"callbacks\": [stream_handler]}\n",
        "            response = conversation_chain.invoke({\"question\": user_prompt, \"npc_mood\": st.session_state.npc_mood}, config)\n",
        "        streamlit_msg_history.add_user_message(user_prompt)\n",
        "        streamlit_msg_history.add_ai_message(response.content)"
      ],
      "metadata": {
        "id": "RRNqqUCux2Kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Starting the Streamlit App"
      ],
      "metadata": {
        "id": "GIs0U2lRU47H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Starting the Streamlit App\n",
        "!streamlit run app.py --server.port=8989 &>/./logs.txt &"
      ],
      "metadata": {
        "id": "RPRHFv4AcgRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setting Up ngrok Tunnel"
      ],
      "metadata": {
        "id": "92ThtCCDU7Cw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting Up ngrok Tunnel\n",
        "from getpass import getpass\n",
        "\n",
        "ngrok_auth_token = getpass('Enter ngrok API Key: ')"
      ],
      "metadata": {
        "id": "1yUedUx5cjkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import yaml\n",
        "\n",
        "# Terminate open tunnels if exist\n",
        "ngrok.kill()\n",
        "\n",
        "# Authenticate ngrok with the token read from the file\n",
        "!ngrok config add-authtoken {ngrok_auth_token}\n",
        "\n",
        "# Open an HTTPS tunnel on port XXXX which you get from your `logs.txt` file\n",
        "ngrok_tunnel = ngrok.connect(8989)\n",
        "print(\"Streamlit App:\", ngrok_tunnel.public_url)"
      ],
      "metadata": {
        "id": "pYvP6SSfcnGk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}