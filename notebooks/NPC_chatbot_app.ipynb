{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#NPC Chatbot App with ChatGPT, LangChain and Streamlit"
      ],
      "metadata": {
        "id": "HSD5WnWeUhpw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Dependencies"
      ],
      "metadata": {
        "id": "9QQK9X0HUdQn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqN2lxJAcVgq"
      },
      "outputs": [],
      "source": [
        "# Install Dependencies\n",
        "!pip install langchain==0.1.12\n",
        "!pip install langchain-openai==0.0.8\n",
        "!pip install langchain-community==0.0.29\n",
        "!pip install streamlit==1.32.2\n",
        "!pip install chromadb==0.4.24\n",
        "!pip install pyngrok==7.1.5\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load OpenAI API Credentials"
      ],
      "metadata": {
        "id": "ZAQUrLx2UmRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load OpenAI API Credentials\n",
        "from getpass import getpass\n",
        "\n",
        "\n",
        "OPENAI_KEY = getpass('Enter Open AI API Key: ')\n"
      ],
      "metadata": {
        "id": "taXEV0M0cbRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Set Environment Variable"
      ],
      "metadata": {
        "id": "opiX93NcUpHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
      ],
      "metadata": {
        "id": "pSJUybmXUwe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Write App Code Header"
      ],
      "metadata": {
        "id": "h1CnU8_1U0yO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Dependencies (No need to re-run if already installed in your Colab)\n",
        "# ... (dependency installations)\n",
        "\n",
        "# Load OpenAI API Credentials (No need to re-run if already set)\n",
        "# ... (API key loading)\n",
        "\n",
        "# Write App Code - REPLACE YOUR EXISTING app.py CONTENT WITH THIS\n",
        "%%writefile app.py\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain_community.chat_message_histories import StreamlitChatMessageHistory\n",
        "from langchain.callbacks.base import BaseCallbackHandler\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_community.vectorstores.chroma import Chroma\n",
        "from langchain.chains import LLMChain\n",
        "from operator import itemgetter\n",
        "\n",
        "import streamlit as st\n",
        "import tempfile\n",
        "import os\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Customize initial app landing page\n",
        "st.set_page_config(page_title=\"NPC Simulation Chatbot\", page_icon=\"ðŸŽ­\")\n",
        "st.title(\"NPC Simulation Chatbot ðŸŽ­\")\n",
        "st.sidebar.header(\"NPC Character Document Upload\")\n",
        "\n",
        "@st.cache_resource(ttl=\"1h\")\n",
        "def configure_npc_agent(uploaded_file):\n",
        "    if uploaded_file is not None:\n",
        "        text_content = uploaded_file.read().decode(\"utf-8\")\n",
        "\n",
        "        # --- Normalize line endings to standard Unix-style (\\n) ---\n",
        "        text_content = text_content.replace('\\\\r\\\\n', '\\\\n').replace('\\\\r', '\\\\n')\n",
        "\n",
        "        # --- NEW DEBUGGING: Print the raw text_content ---\n",
        "        st.write(\"--- **RAW TEXT CONTENT FROM UPLOADED FILE (Line endings normalized)** ---\")\n",
        "        st.write(\"<pre>\" + text_content + \"</pre>\", unsafe_allow_html=True) # Use <pre> for formatting\n",
        "        st.write(\"--- **END RAW TEXT CONTENT** ---\")\n",
        "        # --- END NEW DEBUGGING ---\n",
        "\n",
        "\n",
        "        # --- NEW SECTION PARSING: Line-based parsing ---\n",
        "        lines = text_content.strip().split('\\n') # Split into lines\n",
        "        sections_dict = {}\n",
        "        current_section_name = None\n",
        "        current_section_content = []\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if line.startswith(\"---\") and line.endswith(\"---\"):\n",
        "                if current_section_name:\n",
        "                    sections_dict[current_section_name] = \"\\n\".join(current_section_content).strip()\n",
        "                    current_section_content = [] # Reset content for new section\n",
        "                current_section_name = line.strip('-').strip() # Extract section name\n",
        "            elif current_section_name:\n",
        "                current_section_content.append(line) # Append line to current section\n",
        "\n",
        "        if current_section_name and current_section_content: # Capture last section\n",
        "            sections_dict[current_section_name] = \"\\n\".join(current_section_content).strip()\n",
        "\n",
        "\n",
        "        # --- DEBUGGING: Print the sections_dict ---\n",
        "        st.write(\"--- **DEBUGGING: SECTIONS DICTIONARY AFTER LINE-BASED PARSING** ---\")\n",
        "        st.write(sections_dict) # Print the sections dictionary\n",
        "        st.write(\"--- **END DEBUGGING: SECTIONS DICTIONARY** ---\")\n",
        "        # --- END DEBUGGING ---\n",
        "\n",
        "\n",
        "        character_description = sections_dict.get(\"Character Description\", \"\")\n",
        "        backstory_world_info = sections_dict.get(\"Backstory and World Info\", \"\")\n",
        "        quests_text = sections_dict.get(\"Quests\", \"\")\n",
        "\n",
        "        quests = [q.strip() for q in quests_text.strip().split(\"- \") if q.strip()]\n",
        "\n",
        "\n",
        "        # --- DEBUGGING OUTPUT USING st.write() ---\n",
        "        st.write(\"--- **DEBUGGING INFORMATION - SECTIONS AFTER PROCESSING** ---\")\n",
        "        st.write(\"**Character Description Section:**\")\n",
        "        st.write(character_description)\n",
        "        st.write(\"**Backstory and World Info Section:**\")\n",
        "        st.write(backstory_world_info)\n",
        "        st.write(\"**Quests Section:**\")\n",
        "        st.write(quests_text)\n",
        "        st.write(\"**Extracted Quests List:**\")\n",
        "        st.write(quests)\n",
        "        st.write(\"--- **END DEBUGGING INFORMATION** ---\")\n",
        "        # --- END DEBUGGING OUTPUT ---\n",
        "\n",
        "\n",
        "        # Split backstory and world info into chunks for RAG\n",
        "        text_splitter = CharacterTextSplitter(\n",
        "            separator=\"\\n\",\n",
        "            chunk_overlap=200,\n",
        "            chunk_size=2000,\n",
        "            length_function=len,\n",
        "        )\n",
        "        doc_chunks = text_splitter.create_documents([backstory_world_info])\n",
        "\n",
        "        # Create embeddings and vectorstore for backstory/world info\n",
        "        embeddings_model = OpenAIEmbeddings()\n",
        "        vectordb = Chroma.from_documents(doc_chunks, embeddings_model)\n",
        "        retriever = vectordb.as_retriever()\n",
        "\n",
        "        return character_description, retriever, quests\n",
        "\n",
        "    return None, None, None\n",
        "\n",
        "\n",
        "# Manages live updates to a Streamlit app's display by appending new text tokens\n",
        "class StreamHandler(BaseCallbackHandler):\n",
        "    def __init__(self, container, initial_text=\"\"):\n",
        "        self.container = container\n",
        "        self.text = initial_text\n",
        "\n",
        "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
        "        self.text += token\n",
        "        self.container.markdown(self.text)\n",
        "\n",
        "# UI element to upload text document\n",
        "uploaded_file = st.sidebar.file_uploader(\n",
        "    label=\"Upload NPC Character Text Document\", type=[\"txt\"]\n",
        ")\n",
        "\n",
        "if uploaded_file is None:\n",
        "    st.info(\"Please upload your NPC Character Text Document to continue.\")\n",
        "    st.stop()\n",
        "\n",
        "# Configure NPC agent\n",
        "character_description, retriever, quests = configure_npc_agent(uploaded_file)\n",
        "\n",
        "if character_description is None or retriever is None or quests is None:\n",
        "    st.error(\"Error loading character document. Please check the format.\")\n",
        "    st.stop()\n",
        "\n",
        "# Load LLM\n",
        "chatgpt = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.7, streaming=True)\n",
        "\n",
        "# System prompt for NPC character\n",
        "system_prompt_template = SystemMessagePromptTemplate.from_template(character_description)\n",
        "\n",
        "# RAG Prompt for retrieving NPC/World info\n",
        "rag_prompt_template = ChatPromptTemplate.from_messages([\n",
        "    system_prompt_template,\n",
        "    HumanMessagePromptTemplate.from_template(\"\"\"Use the following context to answer the user question about yourself or the world.\n",
        "                                              Context: {context}\n",
        "                                              Question: {question}\n",
        "                                              If you cannot answer from the context, just say you do not know.\n",
        "                                              Answer in character as described in the system prompt.\"\"\")\n",
        "])\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "rag_chain = (\n",
        "    {\n",
        "        \"context\": itemgetter(\"question\") | retriever | format_docs,\n",
        "        \"question\": itemgetter(\"question\")\n",
        "    }\n",
        "    | rag_prompt_template\n",
        "    | chatgpt\n",
        ")\n",
        "\n",
        "\n",
        "# General conversation prompt (no RAG)\n",
        "conversation_prompt_template = ChatPromptTemplate.from_messages([\n",
        "    system_prompt_template,\n",
        "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
        "])\n",
        "\n",
        "conversation_chain = conversation_prompt_template | chatgpt\n",
        "\n",
        "\n",
        "# Quest related prompts\n",
        "quest_suggestion_prompt_template = ChatPromptTemplate.from_messages([\n",
        "    system_prompt_template,\n",
        "    HumanMessagePromptTemplate.from_template(\"Suggest a quest for the user, keeping in character. If no quests are appropriate, just say 'No quests available right now.'\")\n",
        "])\n",
        "quest_suggestion_chain = quest_suggestion_prompt_template | chatgpt\n",
        "\n",
        "\n",
        "# Conversation Handling\n",
        "streamlit_msg_history = StreamlitChatMessageHistory(key=\"npc_chat_messages\")\n",
        "\n",
        "if len(streamlit_msg_history.messages) == 0:\n",
        "    streamlit_msg_history.add_ai_message(\"Greetings! How can I help you today?\")\n",
        "\n",
        "for msg in streamlit_msg_history.messages:\n",
        "    st.chat_message(msg.type).write(msg.content)\n",
        "\n",
        "if user_prompt := st.chat_input():\n",
        "    st.chat_message(\"human\").write(user_prompt)\n",
        "\n",
        "    # Determine intent: quest, info, or general conversation\n",
        "    if \"quest\" in user_prompt.lower():\n",
        "        if \"give me a quest\" in user_prompt.lower() or \"offer quest\" in user_prompt.lower() or \"i want a quest\" in user_prompt.lower():\n",
        "            if quests:\n",
        "                quest_to_offer = quests.pop(0) # Get the first quest and remove it from the list\n",
        "                with st.chat_message(\"ai\"):\n",
        "                    stream_handler = StreamHandler(st.empty())\n",
        "                    config = {\"callbacks\": [stream_handler]}\n",
        "                    response = conversation_chain.invoke({\"question\": f\"Offer the user the following quest: {quest_to_offer}\"}, config) # Use conversation chain to offer quest in character\n",
        "                streamlit_msg_history.add_user_message(user_prompt)\n",
        "                streamlit_msg_history.add_ai_message(response.content)\n",
        "\n",
        "            else:\n",
        "                 with st.chat_message(\"ai\"):\n",
        "                    stream_handler = StreamHandler(st.empty())\n",
        "                    config = {\"callbacks\": [stream_handler]}\n",
        "                    response = quest_suggestion_chain.invoke({}, config)\n",
        "                 streamlit_msg_history.add_user_message(user_prompt)\n",
        "                 streamlit_msg_history.add_ai_message(response.content)\n",
        "\n",
        "\n",
        "        elif \"what quests\" in user_prompt.lower() or \"tell me about quests\" in user_prompt.lower():\n",
        "            if quests:\n",
        "                quest_list_str = \"\\n\".join([f\"- {q}\" for q in quests])\n",
        "                response_text = f\"Here are the quests I know:\\n{quest_list_str}\"\n",
        "            else:\n",
        "                response_text = \"I don't have any quests for you right now.\"\n",
        "\n",
        "            with st.chat_message(\"ai\"):\n",
        "                st.write(response_text)\n",
        "            streamlit_msg_history.add_user_message(user_prompt)\n",
        "            streamlit_msg_history.add_ai_message(response_text)\n",
        "\n",
        "\n",
        "        else: # Assume general quest related query\n",
        "            with st.chat_message(\"ai\"):\n",
        "                stream_handler = StreamHandler(st.empty())\n",
        "                config = {\"callbacks\": [stream_handler]}\n",
        "                response = conversation_chain.invoke({\"question\": user_prompt}, config) # General conversation in character\n",
        "            streamlit_msg_history.add_user_message(user_prompt)\n",
        "            streamlit_msg_history.add_ai_message(response.content)\n",
        "\n",
        "\n",
        "    elif \"tell me about\" in user_prompt.lower() or \"who are you\" in user_prompt.lower() or \"where am i\" in user_prompt.lower() or \"what is this place\" in user_prompt.lower():\n",
        "        # RAG for NPC/World info\n",
        "        with st.chat_message(\"ai\"):\n",
        "            stream_handler = StreamHandler(st.empty())\n",
        "            config = {\"callbacks\": [stream_handler]}\n",
        "            response = rag_chain.invoke({\"question\": user_prompt}, config)\n",
        "        streamlit_msg_history.add_user_message(user_prompt)\n",
        "        streamlit_msg_history.add_ai_message(response.content)\n",
        "\n",
        "    else:\n",
        "        # General conversation\n",
        "        with st.chat_message(\"ai\"):\n",
        "            stream_handler = StreamHandler(st.empty())\n",
        "            config = {\"callbacks\": [stream_handler]}\n",
        "            response = conversation_chain.invoke({\"question\": user_prompt}, config)\n",
        "        streamlit_msg_history.add_user_message(user_prompt)\n",
        "        streamlit_msg_history.add_ai_message(response.content)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jIVOEGl6TGIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Starting the Streamlit App"
      ],
      "metadata": {
        "id": "GIs0U2lRU47H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Starting the Streamlit App\n",
        "!streamlit run app.py --server.port=8989 &>/./logs.txt &"
      ],
      "metadata": {
        "id": "RPRHFv4AcgRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setting Up ngrok Tunnel"
      ],
      "metadata": {
        "id": "92ThtCCDU7Cw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting Up ngrok Tunnel\n",
        "from getpass import getpass\n",
        "\n",
        "ngrok_auth_token = getpass('Enter ngrok API Key: ')"
      ],
      "metadata": {
        "id": "1yUedUx5cjkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import yaml\n",
        "\n",
        "# Terminate open tunnels if exist\n",
        "ngrok.kill()\n",
        "\n",
        "# Authenticate ngrok with the token read from the file\n",
        "!ngrok config add-authtoken {ngrok_auth_token}\n",
        "\n",
        "# Open an HTTPS tunnel on port XXXX which you get from your `logs.txt` file\n",
        "ngrok_tunnel = ngrok.connect(8989)\n",
        "print(\"Streamlit App:\", ngrok_tunnel.public_url)"
      ],
      "metadata": {
        "id": "pYvP6SSfcnGk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}